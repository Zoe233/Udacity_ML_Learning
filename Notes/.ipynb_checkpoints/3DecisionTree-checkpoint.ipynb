{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Learning\n",
    "## 术语：\n",
    "####  Instances  -- （Input ）\n",
    "#### Concept -- Function \n",
    "    就是世界上的物体之间的映射以及一个集合中的成员关系。\n",
    "#### Target Concept -- Answer \n",
    "#### Hypothesis Class -- 愿意考虑的所有概念的集合\n",
    "#### Sample（Training Set）\n",
    "#### Candidate -- 一个认为可能会是目标概念的概念\n",
    "#### Testing Set \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "Decision Trees: Learning\n",
    "1. Pick Best Attribute  \n",
    "2. Asked Question  \n",
    "3. Follow the answer path  \n",
    "4. Go to 1\n",
    "...recurrent  \n",
    "Util Got An Answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树可以通过简单的线性决策面为你做出非线性决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整哪些参数可以用来提升准确度？\n",
    "从sklearn的官方文档中可以看到用法：   \n",
    "class sklean.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 熵\n",
    "### 熵主要指控制决策树确定在何处分割数据的方式的概念。\n",
    "\n",
    "## 定义：\n",
    "它是测量一系列样本中的不纯度的方式。\n",
    "definition: measure of impurity in a bunch of examples.\n",
    "\n",
    "## 公式：\n",
    "entropy = $-\\sum_{i}P_{i}log_{2}(P_{i})$\n",
    "\n",
    "在使用决策树时，很少需要处理对树底的细节--结论：较低的熵指向更有条理的数据，而且决策树将以此用作事件分类方式。\n",
    "\n",
    "熵基本上与纯度(purity)对立。\n",
    "所有实例都在同一类别中，那么entropy=0;    \n",
    "所有实例都均匀地分布在所有可用类中，则entropy=1.0。   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵计算练习：\n",
    "在节点中有几个慢速样本？写出答案。\n",
    "![title](images/information_gain)\n",
    "前提，p(slow)=0.5, p(fast)=0.5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "answer = -0.5*math.log(0.5, 2) - 0.5*math.log(0.5, 2)\n",
    "print(answer)  # 最不纯的状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息增益 information gain.\n",
    "信息增益定义为父项熵减去分割父项后生成的子项的熵的权重平均值。   \n",
    "information gain = entropy(parent) - [weighted average]entropy(children)\n",
    "\n",
    "\n",
    "决策树算法会最大程度地提高信息增益。   \n",
    "它通过这种方法来选择进行分割的特征，如果特征有多个可获取的不同值，它会尝试最大程度地提高信息增益。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益计算练习：\n",
    "首先选择grade作为分割属性，计算grade对应的信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9182958340544896\n",
      "0.6887218755408672\n",
      "0.31127812445913283\n"
     ]
    }
   ],
   "source": [
    "# ssff -- steep --> ssf\n",
    "#       -- fast --> f\n",
    "\n",
    "# fast这一端点的熵是多少\n",
    "fast_entropy = -1*math.log(1,2)\n",
    "print(abs(fast_entropy))\n",
    "\n",
    "steep_entropy = -2/3 * math.log(2/3, 2) - 1/3 * math.log(1/3, 2)\n",
    "print(steep_entropy)\n",
    "\n",
    "entropy_of_children =3/4 *steep_entropy + 1/4*fast_entropy\n",
    "print(entropy_of_children)\n",
    "\n",
    "initial_total_entropy = -1/2 * math.log(1/2, 2) - 1/2 * math.log(1/2, 2)\n",
    "information_gain = initial_total_entropy - entropy_of_children\n",
    "print(information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 上面就是我们根据grade计算信息增益的结果。   \n",
    "一次类推，计算bumpiness, speed limit的信息增益的大小。  \n",
    "分别计算出来的结果为：   \n",
    "bumpiness of information gain = 0   \n",
    "speed limit of information gain = 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在sklearn.tree.DecisionTreeClassifier中，参数criterion的默认值为'gini'，要想使用信息增益，需要将值改为'entropy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
